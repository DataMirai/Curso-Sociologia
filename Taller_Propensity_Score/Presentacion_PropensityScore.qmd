---
title: "Antes de modelizar, diseña"
format:
  revealjs:
    #incremental: true  
    scrollable: true
    transition: slide
editor: 
  markdown: 
    wrap: 72
---

# 1. Modelizar es un arte

## 1. Modelizar es un arte {auto-animate="true"}

-   Cualquiera puede hacer *arte.*

-   Pero una buena carrera en el mundo del arte requiere de
    **conocimientos en** **técnicas, expresividad herramientas y
    referencias/inspiración.**


## 1. Modelizar es un arte {auto-animate="true"}


-   Cualquiera puede hacer *modelos.*

-   Pero una buena carrera en el mundo de al modelización de datos
    requiere de **conocimientos en modelos, contexto de datos y diseño experimental.**


## 1. Modelizar es un arte {auto-animate="true"}

::: {style="margin-top:180px;"}
Yo apenas puedo explicar *contexto de datos*... pero si puedo ayudar en
**modelos** y en **diseño experimental**.
:::

## 1. Modelizar es un arte {auto-animate="true"}

-   **No hay un modelo mejor que otro**: cada situación requerirá de
    diferentes herramientas.
    

    -   La **Regresión logística**, por ejemplo, es deseable cuando
        funciona porque los parámetros son muy interpretables.
    -   <span style="color:red"> Los **Random Forest** son geniales porque pueden lidiar con
        patrones muy difíciles, pero olvídate de </span>


## 1. Modelizar es un arte {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**Cada modelo tiene sus propiedades.** <br> **Cubriremos los principales
a lo largo de este curso.**
:::

## 1. Modelizar es un arte {auto-animate="true"}

-   Antes de lanzarte a hacer cualquier tipo de modelización, es
    necesario **fijar el contexto de los datos** y estar seguro de que
    **todo será comaprable entre si.**

-   Ten un buen diseño y minimiza la confusión.

-   Sin esto, **los modelos fallarán a la hora de inferenciar.**


# 2. Todos los modelos están equivocados {auto-animate="true"}

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: columns
::: {.column width="30%"}
::: {style="margin-top:10px;"}
![](Imagenes/GeorgeEPBox.jpg){width="300" fig-align="center"}
:::
:::

::: {.column width="70%"}
::: {style="text-align:left; margin-top:150px; margin-left:70px; font-size:55px; margin-bottom:0px; padding:0px;"}
“All models are wrong, but some are useful”
:::

::: {style="text-align:right; margin-top:0px; margin-right:70px; padding:0px; font-size:35px; color:#808080;"}
*- George E. P. Box*
:::
:::
:::

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: columns
::: {.column width="30%"}
::: {style="margin-top:10px;"}
![](Imagenes/GeorgeEPBox.jpg){width="300" fig-align="center"}
:::
:::

::: {.column width="70%"}
::: {style="margin-top:10px;"}
-   Box-Jenkins (procedimientos de *time series*)
-   BoxCox transformations
-   Definición de "robustez" estadística
-   **"Sesión de cerveza del lunes por la noche"**
:::
:::
:::

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: {style="font-size:35px;"}
-   Criterios para la elección de modelos:
:::


::: {style="margin-left:50px; font-size:35px;"}
-   **Parsimonia**
    -   Dado que todos los modelos son erróneos, un científico no puede
        obtener uno que sea "correcto" por muy elaborado que lo haya
        hecho.
-   **Preocupación selectiva**
    -   Hay que conocer el contexto para detectar en qué punto está el
        error.

:::

# 3. Diseño experimental {auto-animate="true"}

## 3. Diseño experimental {auto-animate="true"}

::: {style="margin-top:30px;"}
![](Imagenes/hznah1jzh8fa1111111.png){fig-align="center" width="850"}
:::

## 3. Diseño experimental {auto-animate="true"}

::: {style="margin-top:180px; text-align:center;"}
Permite identificar y cuantificar las causas de un efecto dentro de un
estudio experimental.
:::

## 3. Diseño experimental {auto-animate="true"}

![](Imagenes/u9uxysfx4l1c1.png){fig-align="center"}

## 3.1. Tipos de diseño experimental {auto-animate="true"}

::: {style="margin-top:50px;"}
-   Para poder hacer cualquier estudio, es necesario tener un objetivo,
    normalmente algo con lo que comparar.
:::

## 3.1. Tipos de diseño experimental {auto-animate="true"}

::: {style="margin-top:50px;"}
-   Para poder hacer cualquier estudio, es necesario tener un objetivo,
    normalmente algo con lo que comparar.
:::

::: {style="font-size:55px; margin-top:70px; text-align:center;"}
**¿Pero qué son cosas comparables?**
:::

## 3.1. Tipos de diseño experimental {auto-animate="true"}


::: {style="margin-top:70px;"}
-   Todo estudio necesita un "**tratamiento** *vs* **control**" <br>
    <br>
-   Todo estudio necesita un "**exposición** *vs* **no exposición**"
    <br> <br>
-   Todo estudio necesita un "**hace algo** *vs* **no hace algo**"
:::


## 3.1. Tipos de diseño experimental {auto-animate="true"}

![](Imagenes/Piramide_tipos_diseñoExperimental.png){width="300"
fig-align="center"}

## 3.2. Relevancia y Aplicación {auto-animate="true"}

-   **Estudios Observacionales:** Son muy comunes en sociología debido a
    la facilidad de recopilación de datos y la capacidad de estudiar
    fenómenos en su contexto natural. Sin embargo, pueden estar sujetos
    a sesgos y limitaciones en la causalidad.

-   **Estudios Aleatorizados:** Aunque menos comunes debido a las
    dificultades éticas y logísticas, tienen una gran relevancia en
    sociología cuando es posible implementarlos. Estos estudios
    proporcionan evidencia más sólida sobre las relaciones causales.


## 3.2.1. Ejemplos de Aplicación en Sociología {auto-animate="true"}

-   **Estudios Observacionales:** Un estudio longitudinal que investiga
    el impacto de la educación en la movilidad social a lo largo de
    varias décadas.

-   **Experimentos Aleatorizados:** Un experimento de campo que mide el
    impacto de un programa de intervención social (como tutoría escolar)
    en el rendimiento académico de los estudiantes.


## 3.3. Estudios observacionales {auto-animate="true"}

::: {style="font-size:35px;"}
-   **Caso de estudio:** Se centran en un individuo, grupo o evento
    específico para una observación profunda y detallada.

-   **Estudios transversales:** Recopilan datos a través de
    cuestionarios estructurados. Permiten estudiar la relación entre
    variables en una gran muestra de población.

-   **Estudios de cohorte:** Observan a los mismos sujetos a lo largo de
    un período de tiempo extendido para ver cómo cambian las variables
    estudiadas.

-   **Estudios ecológicos:** Involucran la observación participante y
    entrevistas para comprender las culturas y prácticas de grupos
    específicos.

:::

## 3.4. Estudios experimentales aleatorizados {auto-animate="true"}

::: {style="font-size:30px;"}
-   **Experimentos de Laboratorio:** Se realizan en entornos controlados
    donde los sociólogos manipulan una o más variables para observar los
    efectos en un grupo de sujetos. Por ejemplo, estudiar cómo
    diferentes tipos de comunicación afectan la cooperación en un grupo.

-   **Experimentos de Campo:** Los participantes no saben que están
    siendo observados. Por ejemplo, un experimento que mide la reacción
    de las personas a diferentes estímulos en un entorno laboral real.

-   **Ensayos Aleatorizados Controlados** *(RCT, por sus siglas en
    inglés):* Involucran la asignación aleatoria de participantes a
    grupos experimentales y de control. En sociología se utilizan para
    estudiar el efecto de intervenciones específicas en la conducta
    social.
    
:::

::: {style="font-size:40px; text-align:left;"}
# Para hacer un experimento/modelo hay que tener 2 grupos
:::

# 4. ¿Cómo sé que existe una diferencia entre ambos grupos ?

## 4.1. Conocimiento previo/experto {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**Nada supera el conocimiento del experto.**
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: columns
::: {.column width="45%"}
::: {style="font-size:25px; margin-bottom:15px;"}
-   Lo que el experto hizo:
:::

::: {style="font-size:35px;"}
```{r}
library('tidyverse')

# Métrica:"PIB per capita "
# Fuente:"Cámara de Comercio de España / CGE"
# Clasificación:""
# Unidad:"Euros"
# Escala:"Unidades"
# EscalaFactorPotencia10:"0"
# SonDatosNumericos:"True"
# 
# 
# Url:"https://www.epdata.es/evolucion-pib-per-capita-espana/c2054483-8903-4def-b887-922a328852d3"
# Titulo:"Evolución del PIB per cápita en España desde 1975"
# Subtitulo:""

PIB_datos <- read.csv(
  file = 'data/evolucion_del_pib_per_capita_en_españa_desde_1975_2.csv', 
  sep=';', header=T)

# Lo que el experto hizo:
PIB_datos %>% 
  mutate(Desviacion_Experto = sqrt((PIBxC - mean(PIBxC))^2)/n() )

```
:::
:::

::: {.column width="55%"}
::: {style="margin-top:60px;"}
```{r}
PIB_datos %>% 
  ggplot(aes(AÑO, PIBxC) ) +
  geom_line(size=1.5) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 25),
        axis.title.y = element_text(size = 25))
```
:::

::: {style="font-size:30px; text-align:center;"}

**Media Desviación_experto:** *0.0455*

:::
:::
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: columns
::: {.column width="45%"}
::: {style="font-size:25px; margin-bottom:15px;"}
-   Lo que hemos creado:
:::

::: {style="font-size:30px;"}
```{r}

# Lo que hemos creado:


PIB_2 <- PIB_datos |> 
  mutate(Periodo = case_when(
    between(AÑO, 1856, 1867) ~ 'Liberalismo autoritario'  ,
    between(AÑO, 1868, 1874) ~ 'Sexenio democratico',
    between(AÑO, 1875, 1922) ~ 'Restauracion Borbónica ',
    between(AÑO, 1923, 1930) ~ 'Dictadura Primo de Rivera',
    between(AÑO, 1931,1939)  ~ 'Segunda República',
    between(AÑO, 1940,1975)  ~ 'Dictadura de Francisco Franco',
    between(AÑO, 1976, 2018) ~ 'Transición y Democracia',
    TRUE ~ 'Sin clasificar'
)) |>  
  mutate(Sub_periodo = case_when(
    between(AÑO, 1856, 1863) ~ 'Gobiernos de la unión liberal',  
    between(AÑO, 1864, 1867) ~ 'Crisis de gobernabilidad', 
    between(AÑO, 1931, 1935) ~ 'Primer y segundo Bienios', 
    between(AÑO, 1936, 1939) ~ 'Guerra Civil', 
    between(AÑO, 1940, 1959) ~ 'Primer franquismo / franquismo temprano',
    between(AÑO, 1960, 1975) ~ 'Segundo franquismo / Tardo franquismo',
    between(AÑO, 1976, 1999) ~ 'Antes - Globalización',
    between(AÑO, 2000, 2018) ~ 'Despues - Globalización',
    TRUE ~ 'Sin SubPeriodo'
)) |> 
  mutate('Periodo_Numero' = case_when(
    between(AÑO, 1856, 1867) ~ 1,
    between(AÑO, 1868, 1874) ~ 2,
    between(AÑO, 1875, 1922) ~ 3,
    between(AÑO, 1923, 1930) ~ 4,
    between(AÑO, 1931,1939)  ~ 5,
    between(AÑO, 1940,1975)  ~ 6,
    between(AÑO, 1976, 2018) ~ 7,
    TRUE ~ 0
  )) |> 
mutate(
  'Sub_periodo_numero' = case_when(
    between(AÑO, 1856, 1863) ~ 1,  
    between(AÑO, 1864, 1867) ~ 2, 
    between(AÑO, 1931, 1935) ~ 1, 
    between(AÑO, 1936, 1939) ~ 2, 
    between(AÑO, 1940, 1959) ~ 1,
    between(AÑO, 1960, 1975) ~ 2,
    between(AÑO, 1976, 1999) ~ 1,
    between(AÑO, 2000, 2018) ~ 2,
    TRUE ~ 0
)) 


PIB_2

```
:::
:::

::: {.column width="55%"}
::: {style="margin-top:60px;"}
```{r}

PIB_2 %>% 
  ggplot(aes(AÑO, PIBxC, fill = Periodo) ) +
  geom_boxplot() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.position = "bottom",
        legend.text = element_text(size = 12))
```
:::
:::
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:28px;"}
```{r}

PIB_periodos <-  PIB_2 %>%  
  group_by(Periodo,Periodo_Numero) %>% 
  summarize(
    PIB_medio_periodo = mean(PIBxC),
    Variacion_PIB   = sum(sqrt( (PIBxC - mean(PIBxC))^2 / n() ))) %>% 
  mutate(Desviacion_relativa = Variacion_PIB/PIB_medio_periodo )  %>%  
  mutate(Desviacion_relativa_100 = Variacion_PIB/PIB_medio_periodo * 100)  %>%  
  arrange(Periodo_Numero) %>% 
  select(Periodo, everything(), - Periodo_Numero) %>% 
  ungroup()

PIB_periodos

```
:::

::: {style="font-size:28px;"}
```{r}

PIB_periodos_subperiodos <- PIB_2 |> 
  group_by(Periodo,Periodo_Numero,Sub_periodo, Sub_periodo_numero) |> 
  summarize(
    PIB_medio_periodo = mean(PIBxC),
    Variacion_PIB   = sum(sqrt( (PIBxC - mean(PIBxC))^2 / n() ))) |>  
  mutate(Desviacion_relativa = Variacion_PIB/PIB_medio_periodo * 100) |> 
  arrange(Periodo_Numero,Sub_periodo_numero) |> 
  ungroup() |> 
  select(-c(Periodo_Numero,Sub_periodo_numero)) 

PIB_periodos_subperiodos
```
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:45px"}
El conocimiento del experto tiene que ser reforzado, pero en muchas
ocasiones es mejor reforzarlo usando un modelo bien fundamentado.
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:35px"}

1.  No se tuvo en cuenta el factor de inflación, demasiada poca
    desviación.
2.  Desviación no necesariamente tiene que ser negativo, puede deberse
    al crecimiento económico.
3.  Incluso dentro de un periodo, los subperiodos contienen información.

:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:35px"}
1.  No se tuvo en cuenta el factor de inflación, demasiada poca
    desviación.
2.  Desviación no necesariamente tiene que ser negativo, puede deberse
    al crecimiento económico.
3.  Incluso dentro de un periodo, los subperiodos contienen información.
:::

::: {style="font-size:40px; margin-top:30px; text-align:center;"}
**NUNCA JAMÁS ignorar la descriptiva, jugar con ella es demasiado
valioso**
:::

## 4.2. El *P valor* {auto-animate="true"}


-   *P valor* es la probabilidad de que lo que hayas observado sea no
    aleatorio, asumiendo que la hipótesis nula de la cual se parte es
    cierta.

-   Tener un *P valor* de 0.05 viene a significar que la probabilidad de
    que lo que se está observando NO es aleatorio es de un 5%.


## 4.2. El *P valor* {auto-animate="true"}

::: columns
::: {.column width="50%"}
![](Imagenes/Imagen1.png){width="439" height="459"}
:::

::: {.column width="50%"}
![](Imagenes/Imagen5.jpg){width="464" height="459"}
:::
:::

## 4.2.1. Puntos débiles de los *P valores* {auto-animate="true"}


-   Un *P valor* NO dice nada sobre la importancia clínica o científica.
-   Un *P valor* NO tiene en cuenta el sesgo, sólo el error aleatorio.
-   Un *P valor* «muy bajo» NO implica que la variable o magnitud del
    efecto del tratamiento tenga relevancia.
-   NUNCA se deben comparar *P valores*.


## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Diferencias de medias:

![](Imagenes/diferencias_medias.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Dispersión:

![](Imagenes/Dispersión.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Tamaño de muestra:

![](Imagenes/Tamaño%20de%20muestra.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="margin-top:20px"}
-   En la era de la memoria barata, los grandes volúmenes de datos y los
    procesadores rápidos, las pruebas de normalidad deberían rechazar
    siempre la nulidad de la distribución normal para muestras grandes
    (aunque no increíblemente grandes).
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

```{r}
x <- replicate(100, 
  { # generates 100 different tests on each distribution
    c(
      shapiro.test(rnorm(10))$p.value,   #$
      shapiro.test(rnorm(100))$p.value,  #$
      shapiro.test(rnorm(1000))$p.value, #$
      shapiro.test(rnorm(5000))$p.value) #$
  } # rnorm gives a random draw from the normal distribution
)
```


```{r}
rownames(x) <- c("n10","n100","n1000","n5000")
```


::: {style="font-size:35px; margin-top:30px;"}
```{r}
x
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:35px; margin-top:30px;"}

```{r}
x<0.05
```

:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:30px; margin-top:20px;"}
- Proporción de desviaciones significativas:
:::

::: {style="margin-top:0px; text-align:center;"}

```{r}
rowMeans(x<0.05) # the proportion of significant deviations
# Proporcion de desviaciones significativas
# Proporción de veces que  que se rechaza la hipotesis nula

```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:50px"}
¿Existen pruebas convincentes de alguna desviación del ideal gaussiano?
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:50px"}
El test apunta tener datos perfectos sobre una normal. Eso no pasa.
:::

::: {style="font-size:40px; text-align:left;"}
# Si los *P valores* no son buenos indicativos <br> Entonces, ¿Qué se debe usar en estos casos?
:::

# 5. Standarized mean deviation *(SMD)*

*Desviación de media estandarizada*

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

-   La **standarized mean deviation** *(SMD)* o diferencias de medias
    estandarizadas son básicamente la diferencia entre las medias o
    proporciones de una variable, estratificando por otra.

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="margin-top:70px;"}
$$
SMD = \frac{M_1 - M_2}{\sqrt{\frac{SD_1 + SD_2}{2}}} 
$$
:::

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="margin-top:70px;"}
$$
SMD = \frac{M_1 - M_2}{\sqrt{\frac{SD_1 + SD_2}{2}}} 
$$
:::

::: {style="font-size:25px; margin-top:70px;"}
Donde :

-   $M_1$ es la media o proporción del grupo 1
-   $M_2$ es la media o proporción del grupo 2
-   $S_1$ es desviación estándar del grupo 1
-   $S_2$ es desviación estándar del grupo 2

:::

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="font-size:30px; margin-top:30px; margin-bottom:0px; padding:0px;"}
-   En el mundo de la medicina está aceptado que dos grupos son
    diferentes si presentan una SMD \>0.1 (o del 10%).

-   Las SMD se calculan entorno a la exposición.
:::

![](Imagenes/tipos_muestras.png){fig-align="center" width="1000"}

# ¿y por qué son mejores que el *P valor*?

# Bienvenidos a las bases de inferencia causal

# 6. Confusión

## 6.1. La paradoja de Simpson {auto-animate="true"}

![](Imagenes/paradoja_simpson.jpg){fig-align="center"}

## 6.2. Las variables externas {auto-animate="true"}

![](Imagenes/efectos_externos.png){fig-align="center"}

::: {style="text-align:center; font-size:28px"}
*"La gripe se elimina con paracetamol en 7 días. Si no, se cura sola en una semana."*
:::

# ¿Cómo lidiamos con los factores externos?

# 7. Propensity score

## 7. Propensity score {auto-animate="true"}

::: {style="margin-top:15px;"}
-   Para cada sujeto, calcular la probabilidad (puntuación de
    propensión) de recibir la exposición en función de unas covariables
    observadas, mediante un modelo de clasificación.
:::

## 7.1. Criterios para seleccionar las covariables {auto-animate="true"}

-   Se pueden seleccionar covariables que...

    -   pueden **influir en el proceso de selección** del tratamiento.
    -   pueden **inducir equilibrio**, independientemente de su
        significación estadística o colinealidad con otras variables del
        modelo.
    -   incluyan los **factores de riesgo** y los **términos de
        interacción** importantes entre los factores de confusión.


## 7.1. Criterios para seleccionar las covariables {auto-animate="true"}

Además se debe considerar que:

-   No todas las covariables tienen la misma importancia.
-   Se seleccionarán únicamente aquellas que probablemente afecten al
    resultado.
-   No se deben utilizar los datos de resultados en el proceso de
    Propensity Score.

## 7.2. Análisis de *PS* paso a paso {auto-animate="true"}

![](Imagenes/Propensity_pasos.jpg){fig-align="center"}

## 8. Emparejamiento por puntuación de propensión {auto-animate="true"}

## 9. IPWRA {auto-animate="true"}

# 10. Ejercicio práctico: programar un propensity score

## 10. Ejercicio práctico: programar un propensity score {auto-animate="true"}

::: {style="font-size:28px;"}
1.  Elegir qué variables deben estar equilibradas por población a nivel
    de azar.
2.  Crear una tabla con *TableOne* para ver las *SMD* y su nivel basal.
3.  Aplicar un algoritmo de clasificación para ver las propensiones
    (usaremos un **glm** para no complicarnos).
4.  Crear la probabilidad de clasificación.
5.  Crear una variable IPTW / matching según las necesidades.
6.  Rehacer *TableOne* pero esta vez con los pesos o las variables de
    matching, y volver a las *SMD*.
7.  Asegurar que los *SMD* de las variables del punto primero están por
    debajo de 0.1.
8.  Visualizar los IPWT e individuos extrañamente alejados.
:::
