---
title: "Antes de modelizar, diseña"
format:
  revealjs:
    #incremental: true  
    scrollable: true
    transition: slide
editor: 
  markdown: 
    wrap: 72
---

# 1. Modelizar es un arte

## 1. Modelizar es un arte {auto-animate="true"}

-   Cualquiera puede hacer *arte.*

-   Pero una buena carrera en el mundo del arte requiere de
    **conocimientos en** **técnicas, expresividad herramientas y
    referencias/inspiración.**

## 1. Modelizar es un arte {auto-animate="true"}

-   Cualquiera puede hacer *modelos.*

-   Pero una buena carrera en el mundo de al modelización de datos
    requiere de **conocimientos en modelos, contexto de datos y diseño
    experimental.**

## 1. Modelizar es un arte {auto-animate="true"}

::: {style="margin-top:180px;"}
Yo apenas puedo explicar *contexto de datos*... pero si puedo ayudar en
**modelos** y en **diseño experimental**.
:::

## 1. Modelizar es un arte {auto-animate="true"}

-   **No hay un modelo mejor que otro**: cada situación requerirá de
    diferentes herramientas.

    -   La **Regresión logística**, por ejemplo, es deseable cuando
        funciona porque los parámetros son muy interpretables.
    -   Los **Random Forest** son geniales porque pueden lidiar con
        patrones muy difíciles, pero olvídate de su interpretación.

## 1. Modelizar es un arte {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**Cada modelo tiene sus propiedades.** <br> **Cubriremos los principales
a lo largo de este curso.**
:::

## 1. Modelizar es un arte {auto-animate="true"}

-   Antes de lanzarte a hacer cualquier tipo de modelización, es
    necesario **fijar el contexto de los datos** y estar seguro de que
    **todo será comaprable entre si.**

-   Ten un buen diseño y minimiza la confusión.

-   Sin esto, **los modelos fallarán a la hora de inferenciar.**

## 1. Modelizar es un arte {auto-animate="true"}

![](Imagenes/extrapolating.png){fig-align="center"}

# 2. Todos los modelos están equivocados {auto-animate="true"}

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: columns
::: {.column width="30%"}
::: {style="margin-top:10px;"}
![](Imagenes/GeorgeEPBox.jpg){width="300" fig-align="center"}
:::
:::

::: {.column width="70%"}
::: {style="text-align:left; margin-top:150px; margin-left:70px; font-size:55px; margin-bottom:0px; padding:0px;"}
“All models are wrong, but some are useful”
:::

::: {style="text-align:right; margin-top:0px; margin-right:70px; padding:0px; font-size:35px; color:#808080;"}
*- George E. P. Box*
:::
:::
:::

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: columns
::: {.column width="30%"}
::: {style="margin-top:10px;"}
![](Imagenes/GeorgeEPBox.jpg){width="300" fig-align="center"}
:::
:::

::: {.column width="70%"}
::: {style="margin-top:10px;"}
-   Box-Jenkins (procedimientos de *time series*)
-   BoxCox transformations
-   Definición de "robustez" estadística
-   **"Sesión de cerveza del lunes por la noche"**
:::
:::
:::

## 2. Todos los modelos están equivocados {auto-animate="true"}

::: {style="font-size:35px;"}
-   Criterios para la elección de modelos, según Box:
:::

::: {style="margin-left:50px; font-size:35px;"}
-   **Parsimonia**
    -   Dado que todos los modelos son erróneos, un científico no puede
        obtener uno que sea "correcto" por muy elaborado que lo haya
        hecho.
-   **Preocupación selectiva**
    -   Hay que conocer el contexto para detectar en qué punto está el
        error.
:::

# 3. Diseño experimental {auto-animate="true"}

## 3. Diseño experimental {auto-animate="true"}

::: {style="margin-top:30px;"}
![](Imagenes/hznah1jzh8fa1111111.png){fig-align="center" width="850"}
:::

## 3. Diseño experimental {auto-animate="true"}

::: {style="margin-top:160px; text-align:center;"}
**Diseño experimental**: rama de la estadística que permite identificar
y cuantificar el tamaño de un efecto dentro de un estudio, miniminzando
la confusión y permitiendo causalidad.
:::

## 3. Diseño experimental {auto-animate="true"}

![](Imagenes/u9uxysfx4l1c1.png){fig-align="center"}

## 3.1. Tipos de diseño experimental {auto-animate="true"}

::: {style="margin-top:50px;"}
Para poder hacer cualquier estudio, es necesario tener un objetivo,
normalmente algo con lo que comparar.
:::

## 3.1. Tipos de diseño experimental {auto-animate="true"}

::: {style="margin-top:50px;"}
Para poder hacer cualquier estudio, es necesario tener un objetivo,
normalmente algo con lo que comparar.
:::

::: {style="font-size:55px; margin-top:70px; text-align:center;"}
**¿Pero qué son cosas comparables?**
:::

## 3.1. Tipos de diseño experimental {auto-animate="true"}

::: {style="margin-top:70px;"}
-   Todo estudio necesita un "**tratamiento** *vs* **control**" <br>
    <br>
-   Todo estudio necesita un "**exposición** *vs* **no exposición**"
    <br> <br>
-   Todo estudio necesita un "**hace algo** *vs* **no hace algo**"
:::

## 3.1. Tipos de diseño experimental {auto-animate="true"}

![](Imagenes/Piramide_tipos_diseñoExperimental.png){width="300"
fig-align="center"}

## 3.2. Relevancia y Aplicación {auto-animate="true"}

-   **Estudios Observacionales:** Son muy comunes en sociología debido a
    la facilidad de recopilación de datos y la capacidad de estudiar
    fenómenos en su contexto natural. Sin embargo, pueden estar sujetos
    a sesgos y limitaciones en la causalidad.

-   **Estudios Aleatorizados:** Aunque menos comunes debido a las
    dificultades éticas y logísticas, tienen una gran relevancia en
    sociología cuando es posible implementarlos. Estos estudios
    proporcionan evidencia más sólida sobre las relaciones causales.

## 3.2.1. Ejemplos de Aplicación en Sociología {auto-animate="true"}

-   **Estudios Observacionales:** Un estudio longitudinal que investiga
    el impacto de la educación en la movilidad social a lo largo de
    varias décadas.

-   **Experimentos Aleatorizados:** Un experimento de campo que mide el
    impacto de un programa de intervención social (como tutoría escolar)
    en el rendimiento académico de los estudiantes.

## 3.3. Estudios observacionales {auto-animate="true"}

::: {style="font-size:35px;"}
-   **Caso de estudio:** Se centran en un individuo, grupo o evento
    específico para una observación profunda y detallada.

-   **Estudios transversales:** Recopilan datos a través de
    cuestionarios estructurados. Permiten estudiar la relación entre
    variables en una gran muestra de población.

-   **Estudios de cohorte:** Observan a los mismos sujetos a lo largo de
    un período de tiempo extendido para ver cómo cambian las variables
    estudiadas.

-   **Estudios ecológicos:** Involucran la observación participante y
    entrevistas para comprender las culturas y prácticas de grupos
    específicos.
:::

## 3.4. Estudios experimentales aleatorizados {auto-animate="true"}

::: {style="font-size:30px;"}
-   **Experimentos de Laboratorio:** Se realizan en entornos controlados
    donde los sociólogos manipulan una o más variables para observar los
    efectos en un grupo de sujetos. Por ejemplo, estudiar cómo
    diferentes tipos de comunicación afectan la cooperación en un grupo.

-   **Experimentos de Campo:** Los participantes no saben que están
    siendo observados. Por ejemplo, un experimento que mide la reacción
    de las personas a diferentes estímulos en un entorno laboral real.

-   **Ensayos Aleatorizados Controlados** *(RCT, por sus siglas en
    inglés):* Involucran la asignación aleatoria de participantes a
    grupos experimentales y de control. En sociología se utilizan para
    estudiar el efecto de intervenciones específicas en la conducta
    social.
:::

::: {style="font-size:40px; text-align:left;"}
# Para hacer un experimento/modelo hay que tener 2 grupos
:::

# 4. ¿Cómo sabemos que existe una diferencia entre 2 grupos ?

## 4.1. Conocimiento previo/experto {auto-animate="true"}

## 4.1. Conocimiento previo/experto {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**Nada supera el conocimiento del experto.**
:::

## 4.1. Conocimiento previo/experto {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**Nada supera el conocimiento del experto. Pero...**
:::

## 4.1. Conocimiento previo/experto {auto-animate="true"}

::: {.scroll-container style="overflow-y: scroll; height: 1300px;"}
![](Imagenes/pelea_variables.jpg){fig-align="center"}
::: 

## 4.1. Conocimiento previo/experto {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:45px"}
**Nada supera el conocimiento del experto...**
:::

::: {style="text-align:center; margin-top:100px; font-size:45px"}
**...pero hay que ayudarle a que tome la dirección correcta.**
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

Un economista tiene una hipótesis. Los periodos históricos con baja
varianza en la tasa del PIBxC han sido periodos democráticamnete
estables.

Para poder estimar esa variabilidad utilizo la varianza:

$$
varianza = \frac{\sum\sqrt{(PIBxC - \overline{PIBxC})^2}}{n} 
$$

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: columns
::: {.column width="45%"}
::: {style="font-size:25px; margin-bottom:15px;"}
-   Lo que el experto hizo:
:::

::: {style="font-size:35px;"}
```{r}
library('tidyverse')

# Métrica:"PIB per capita "
# Fuente:"Cámara de Comercio de España / CGE"
# Clasificación:""
# Unidad:"Euros"
# Escala:"Unidades"
# EscalaFactorPotencia10:"0"
# SonDatosNumericos:"True"
# 
# 
# Url:"https://www.epdata.es/evolucion-pib-per-capita-espana/c2054483-8903-4def-b887-922a328852d3"
# Titulo:"Evolución del PIB per cápita en España desde 1975"
# Subtitulo:""

PIB_datos <- read.csv(
  file = 'data/evolucion_del_pib_per_capita_en_españa_desde_1975_2.csv', 
  sep=';', header=T)

# Lo que el experto hizo:
PIB_datos %>% 
  mutate(Desviacion_Experto = sqrt((PIBxC - mean(PIBxC))^2)/n() )

```
:::
:::

::: {.column width="55%"}
::: {style="margin-top:60px;"}
```{r}
PIB_datos %>% 
  ggplot(aes(AÑO, PIBxC) ) +
  geom_line(size=1.5) +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 25),
        axis.title.y = element_text(size = 25))
```
:::

::: {style="font-size:30px; text-align:center;"}
**Media Desviación_experto:** *0.0455*
:::
:::
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="text-align:center; margin-top:180px; font-size:45px"}
**¿0.0455 qué?**
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: columns
::: {.column width="45%"}
::: {style="font-size:25px; margin-bottom:15px;"}
-   Lo que hemos creado:
:::

::: {style="font-size:30px;"}
```{r}

# Lo que hemos creado:


PIB_2 <- PIB_datos |> 
  mutate(Periodo = case_when(
    between(AÑO, 1856, 1867) ~ 'Liberalismo autoritario'  ,
    between(AÑO, 1868, 1874) ~ 'Sexenio democratico',
    between(AÑO, 1875, 1922) ~ 'Restauracion Borbónica ',
    between(AÑO, 1923, 1930) ~ 'Dictadura Primo de Rivera',
    between(AÑO, 1931,1939)  ~ 'Segunda República',
    between(AÑO, 1940,1975)  ~ 'Dictadura de Francisco Franco',
    between(AÑO, 1976, 2018) ~ 'Transición y Democracia',
    TRUE ~ 'Sin clasificar'
)) |>  
  mutate(Sub_periodo = case_when(
    between(AÑO, 1856, 1863) ~ 'Gobiernos de la unión liberal',  
    between(AÑO, 1864, 1867) ~ 'Crisis de gobernabilidad', 
    between(AÑO, 1931, 1935) ~ 'Primer y segundo Bienios', 
    between(AÑO, 1936, 1939) ~ 'Guerra Civil', 
    between(AÑO, 1940, 1959) ~ 'Primer franquismo / franquismo temprano',
    between(AÑO, 1960, 1975) ~ 'Segundo franquismo / Tardo franquismo',
    between(AÑO, 1976, 1999) ~ 'Antes - Globalización',
    between(AÑO, 2000, 2018) ~ 'Despues - Globalización',
    TRUE ~ 'Sin SubPeriodo'
)) |> 
  mutate('Periodo_Numero' = case_when(
    between(AÑO, 1856, 1867) ~ 1,
    between(AÑO, 1868, 1874) ~ 2,
    between(AÑO, 1875, 1922) ~ 3,
    between(AÑO, 1923, 1930) ~ 4,
    between(AÑO, 1931,1939)  ~ 5,
    between(AÑO, 1940,1975)  ~ 6,
    between(AÑO, 1976, 2018) ~ 7,
    TRUE ~ 0
  )) |> 
mutate(
  'Sub_periodo_numero' = case_when(
    between(AÑO, 1856, 1863) ~ 1,  
    between(AÑO, 1864, 1867) ~ 2, 
    between(AÑO, 1931, 1935) ~ 1, 
    between(AÑO, 1936, 1939) ~ 2, 
    between(AÑO, 1940, 1959) ~ 1,
    between(AÑO, 1960, 1975) ~ 2,
    between(AÑO, 1976, 1999) ~ 1,
    between(AÑO, 2000, 2018) ~ 2,
    TRUE ~ 0
)) 


PIB_2

```
:::
:::

::: {.column width="55%"}
::: {style="margin-top:60px;"}
```{r}

PIB_2 %>% 
  ggplot(aes(AÑO, PIBxC, fill = Periodo) ) +
  geom_boxplot() +
  theme(axis.text.x = element_text(size = 20),
        axis.text.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.position = "bottom",
        legend.text = element_text(size = 12))
```
:::
:::
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:28px;"}
```{r}

PIB_periodos <-  PIB_2 %>%  
  group_by(Periodo,Periodo_Numero) %>% 
  summarize(
    PIB_medio_periodo = mean(PIBxC),
    Variacion_PIB   = sum(sqrt( (PIBxC - mean(PIBxC))^2 / n() ))) %>% 
  mutate(Desviacion_relativa = Variacion_PIB/PIB_medio_periodo )  %>%  
  mutate(Desviacion_relativa_100 = Variacion_PIB/PIB_medio_periodo * 100)  %>%  
  arrange(Periodo_Numero) %>% 
  select(Periodo, everything(), - Periodo_Numero) %>% 
  ungroup()

PIB_periodos
```
:::

::: {style="font-size:28px;"}
```{r}

PIB_periodos_subperiodos <- PIB_2 |> 
  group_by(Periodo,Periodo_Numero,Sub_periodo, Sub_periodo_numero) |> 
  summarize(
    PIB_medio_periodo = mean(PIBxC),
    Variacion_PIB   = sum(sqrt( (PIBxC - mean(PIBxC))^2 / n() ))) |>  
  mutate(Desviacion_relativa = Variacion_PIB/PIB_medio_periodo * 100) |> 
  arrange(Periodo_Numero,Sub_periodo_numero) |> 
  ungroup() |> 
  select(-c(Periodo_Numero,Sub_periodo_numero)) 

PIB_periodos_subperiodos
```
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="text-align:center; margin-top:80px; font-size:45px"}
El conocimiento del experto tiene una buena intuición, pero por si
acaso, hay que reforzarlo usando un modelo bien fundamentado.
:::

::: {style="text-align:center; margin-top:50px; font-size:45px"}
Debemos estar en las mismas unidades para poder comparar dos fenómenos.
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:35px"}
1.  No se tuvo en cuenta la tendencia en la serie de tiempo, sea debida
    a la inflación o por revolución tecnológica.
2.  Desviación no necesariamente significa negativo, existe la
    desviación positiva por crecimiento económico.
3.  Dentro de un periodo, hay subperiodos. Estos contienen información.
    No desperdiciarla.
:::

## 4.1.1. Conocimiento previo/experto: Caso práctico {auto-animate="true"}

::: {style="font-size:35px"}
1.  No se tuvo en cuenta la tendencia en la serie de tiempo, sea debida
    a la inflación o por revolución tecnológica.
2.  Desviación no necesariamente significa negativo, existe la
    desviación positiva por crecimiento económico.
3.  Dentro de un periodo, hay subperiodos. Estos contienen información.
    No desperdiciarla.
:::

::: {style="font-size:40px; margin-top:30px; text-align:center;"}
**NUNCA NUNCA NUNCA ignorar la descriptiva**
:::

::: {style="font-size:40px; text-align:left;"}
# ¿Qué criterio usar para comparar dos grupos?
:::

## 4.2. El *P valor* {auto-animate="true"}

-   **P valor** es la *probabilidad de que lo que hayas observado sea no
    aleatorio, asumiendo que la hipótesis nula de la cual se parte es
    cierta.*

-   Tener un *P valor* de 0.05 viene a significar que la probabilidad de
    que lo que se está observando NO es aleatorio es de un 5%.

## 4.2. El *P valor* {auto-animate="true"}

::: columns
::: {.column width="50%"}
![](Imagenes/Imagen1.png){width="439" height="459"}
:::

::: {.column width="50%"}
![](Imagenes/Imagen5.jpg){width="464" height="459"}
:::
:::

## 4.2.1. Puntos débiles de los *P valores* {auto-animate="true"}

-   Un *P valor* NO dice nada sobre la importancia clínica o científica.
-   Un *P valor* NO tiene en cuenta el sesgo, sólo el error aleatorio.
-   Un *P valor* «muy bajo» NO implica que la variable o magnitud del
    efecto del tratamiento tenga relevancia.
-   NUNCA se deben comparar *P valores*.

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Diferencias de medias:

![](Imagenes/diferencias_medias.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Dispersión:

![](Imagenes/Dispersión.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

-   Tamaño de muestra:

![](Imagenes/Tamaño%20de%20muestra.png){width="300" fig-align="center"}

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="margin-top:20px"}
-   En la era de la memoria barata, los grandes volúmenes de datos y los
    procesadores rápidos, las pruebas de normalidad deberían rechazar
    siempre la nulidad de la distribución normal para muestras grandes
    (aunque no increíblemente grandes).
:::

-   Hagamos un ejemplo con test de normalidad para diversas cantidades
    de datos (10,100,1000,5000)

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

```{r}
x <- replicate(100, 
  { # genera 100 pruebas diferentes para los 4 tamaños de muestra, cada una  en cada distribución
    c(
      shapiro.test(rnorm(10))$p.value,   #$
      shapiro.test(rnorm(100))$p.value,  #$
      shapiro.test(rnorm(1000))$p.value, #$
      shapiro.test(rnorm(5000))$p.value) #$
  } # rnorm gives a random draw from the normal distribution
)
```

```{r}
rownames(x) <- c("n10","n100","n1000","n5000")
```

::: {style="font-size:35px; margin-top:30px;"}
```{r}
x
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:35px; margin-top:30px;"}
```{r}
x<0.05
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

```{r}
x <- replicate(100, 
  { # genera 100 pruebas diferentes para los 4 tamaños de muestra, cada una  en cada distribución
    c(
      shapiro.test(rnorm(10  ) + c(1,0,2,0,1))$p.value, #$
      shapiro.test(rnorm(100 ) + c(1,0,2,0,1))$p.value, #$
      shapiro.test(rnorm(1000) + c(1,0,2,0,1))$p.value, #$
      shapiro.test(rnorm(5000) + c(1,0,2,0,1))$p.value)
  }
)
```

```{r}
rownames(x) <- c("n10","n100","n1000","n5000")
```

::: {style="font-size:35px; margin-top:30px;"}
```{r}
x
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:35px; margin-top:30px;"}
- ¿Se rechaza la hipótesis nula?

```{r}
x < 0.05
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:30px; margin-top:20px;"}
-   Proporción de desviaciones significativas:
:::

::: {style="margin-top:0px; text-align:center;"}
```{r}
rowMeans( x < 0.05) # the proportion of significant deviations
# Proporcion de desviaciones significativas
# Proporción de veces que  que se rechaza la hipotesis nula

```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

```{r}
x <- replicate(100, 
  { # genera 100 pruebas diferentes para los 4 tamaños de muestra, cada una  en cada distribución
    c(
      shapiro.test(rnorm(10  ) + c(1,0,4,0,1))$p.value, #$
      shapiro.test(rnorm(100 ) + c(1,0,4,0,1))$p.value, #$
      shapiro.test(rnorm(1000) + c(1,0,4,0,1))$p.value, #$
      shapiro.test(rnorm(5000) + c(1,0,4,0,1))$p.value)
  }
)
```

```{r}
rownames(x) <- c("n10","n100","n1000","n5000")
```

::: {style="font-size:35px; margin-top:30px;"}
```{r}
x
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:35px; margin-top:30px;"}
- ¿Se rechaza la hipótesis nula?

```{r}
x < 0.05
```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="font-size:30px; margin-top:20px;"}
-   Proporción de desviaciones significativas:
:::

::: {style="margin-top:0px; text-align:center;"}
```{r}
rowMeans( x < 0.05) # the proportion of significant deviations
# Proporcion de desviaciones significativas
# Proporción de veces que  que se rechaza la hipotesis nula

```
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:50px"}
¿Existen pruebas convincentes de alguna desviación del ideal gaussiano?
:::

## 4.2.2. Dependencias de los *P valores*? {auto-animate="true"}

::: {style="text-align:center; margin-top:130px; font-size:50px"}
El test apunta tener datos perfectos sobre una normal. Eso no pasa.
:::

::: {style="font-size:40px; text-align:left;"}
# Si los *P valores* no son buenos indicativos <br> Entonces, ¿Qué se debe usar en estos casos?
:::

# 5. Standarized mean deviation *(SMD)*

*Desviación de media estandarizada*

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

-   La **standarized mean deviation** *(SMD)*, o diferencias de medias
    estandarizadas, son básicamente la diferencia entre las medias o
    proporciones de una variable, estratificando por otra.

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="margin-top:70px;"}
$$
SMD = \frac{M_1 - M_2}{\sqrt{\frac{SD_1 + SD_2}{2}}} 
$$
:::

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="margin-top:70px;"}
$$
SMD = \frac{M_1 - M_2}{\sqrt{\frac{SD_1 + SD_2}{2}}} 
$$
:::

::: {style="font-size:25px; margin-top:70px;"}
Donde :

-   $M_1$ es la media o proporción del grupo 1
-   $M_2$ es la media o proporción del grupo 2
-   $S_1$ es desviación estándar del grupo 1
-   $S_2$ es desviación estándar del grupo 2
:::

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: {style="font-size:30px; margin-top:30px; margin-bottom:0px; padding:0px;"}
-   En el mundo de la medicina está aceptado que dos grupos son
    diferentes si presentan una SMD \>0.1 (o del 10%).

-   Las SMD se calculan entorno a la exposición.
:::

![](Imagenes/tipos_muestras.png){fig-align="center" width="1000"}

# ¿y por qué son mejores que el *P valor*?

## 5. Standarized mean deviation *(SMD)* {auto-animate="true"}

::: columns
::: {.column width="50%"}
**SMD**

-   Proporciona una medida de la magnitud del efecto.

-   Las SMD son una medida estandarizada.

-   **Consistencia:** menos sensible al tamaño de la muestra.
:::

::: {.column width="50%"}
**P valor**

-   Significación Binaria: o son diferentes o no lo son. Simplista.

-   Dependencia del tamaño de muestra.

-   **No indica tamaño del efecto**.
:::
:::

# Bienvenidos a las bases de inferencia causal

# 6. Inferencia causal

## 6. Inferencia causal

::: {style="text-align:center; margin-top:120px; font-size:55px; margin-bottom:0px; padding:0px;"}
**"Predecir la exposición"**
:::

::: {style="text-align:right; margin-top:70px; padding:0px; font-size:35px; color:#808080;"}
*-  Richard McElreath, Statistical Rethinking*
:::

## 6. Inferencia causal

::: {style="text-align:center; margin-top:120px; font-size:55px; margin-bottom:0px; padding:0px;"}
**"Predecir la exposición implica que se puede simular la exposición"**
:::

::: {style="text-align:right; margin-top:70px; padding:0px; font-size:35px; color:#808080;"}
*-  Richard McElreath, Statistical Rethinking*
:::

## 6. Inferencia causal

-   ¿Qué hubiera pasado si todos los individuos hubieran estado
    expuestos?
-   ¿Qué hubiera pasado si ningún individuo hubiera estado expuesto?

## 6. Inferencia causal

::: {style="text-align:center; margin-top:80px; font-size:45px; margin-bottom:0px; padding:0px;"}
**"Mete en un modelo todas las variables que se te ocurran e interpreta
entonces todos los coeficientes como efectos causales. A ver qué sale."**
:::

::: {style="text-align:right; margin-top:70px; padding:0px; font-size:35px; color:#808080;"}
*- Aitor Gonzalez, tu estadístico de confianza. <br> Y cada día el de menos gente.*
:::

## 6. Inferencia causal

**Ciencia antes que estadística:**

- Supongamos que tenemos un diagrama del modelo. Y que el diagrama es
correcto. Esta es la principal asunción de toda la inferencia causal.

- Las técnicas de inferencia causal son sólo herramientas técnicas que nos
ayudarán a estimar el efecto. Pero si nuestras asunciones son
incorrectas, no hay técnica que nos salve.

::: {style="text-align:center; margin-top:10px;"}
**¿Qué nos lo impide?**
:::

# 7. La confusión

## 7. La confusión

- Situación en la que la relación entre una variable independiente y una
variable dependiente se distorsiona por la influencia de una tercera
variable, conocida como **variable de confusión** o confusora.

## 7.1. La paradoja de Simpson {auto-animate="true"}

![](Imagenes/paradoja_simpson.jpg){fig-align="center"}

## 7.2. Efecto placebo {auto-animate="true"}

![](Imagenes/efectos_externos.png){fig-align="center"}

*"La gripe se elimina con paracetamol en 7 días. Si no, se cura sola en
una semana."*

::: {style="text-align:right; margin-right:70px; padding:0px; font-size:30px; color:#808080;"}
*- Att: La confusión*
:::

# ¿Cómo lidiamos con la confusión?

# 8. Propensity score

## 8. Propensity score {auto-animate="true"}

::: {style="margin-top:50px;font-size:65px"}
El *Emparejamiento por Puntuación de Propensión (PSM)* es una técnica
estadística utilizada para estimar el efecto causal de un tratamiento o
intervención **cuando no es posible realizar un experimento aleatorio.**
:::

## 8. Propensity score: Objetivo {auto-animate="true"}

::: {style="margin-top:50px;font-size:50px"}
-   *Reducir el sesgo de confusión*: Controla por variables observadas
    que podrían influir en la asignación del tratamiento y en el
    resultado.
-   *Simular un ensayo aleatorio*: trata de igualar el grupo de control
    al grupo experiemntal.
:::

## 8. Propensity score: técnica {auto-animate="true"}

::: {style="margin-top:50px;font-size:55px"}
-   Para cada sujeto, calcular la probabilidad (puntuación de
    propensión) de recibir la exposición en función de unas covariables
    observadas, mediante un modelo de clasificación.
-   ~~Respuesta~~ $exposición \sim covariables$
:::

## 8.1. Criterios para seleccionar las covariables {auto-animate="true"}

-   Se pueden seleccionar covariables que...

    -   pueden **influir en el proceso de selección** del tratamiento.
    -   pueden **inducir equilibrio**, independientemente de su
        significación estadística o colinealidad con otras variables del
        modelo.
    -   incluyan los **factores de riesgo** y los **términos de
        interacción** importantes entre los factores de confusión.

## 8.1. Criterios para seleccionar las covariables {auto-animate="true"}

Además se debe considerar que:

-   Algunas variables **no deben equilibrarse** (características innatas
    de los grupos)
-   Se seleccionarán únicamente aquellas que probablemente afecten al
    resultado.
-   No se deben utilizar los datos de resultados en el proceso de
    Propensity Score.

## 8.2. Análisis de *PS* paso a paso {auto-animate="true"}

![](Imagenes/Propensity_pasos.jpg){fig-align="center"}

## 8.3. Emparejamiento por puntuación de propensión {auto-animate="true"}

1.  **Estimación de la Puntuación de Propensión**: Se calcula la
    probabilidad de cada sujeto de recibir el tratamiento basado en las
    covariables.

2.  **Emparejamiento**: Cada sujeto tratado se empareja con uno o más
    sujetos de control con puntuaciones de propensión similares.

3.  **Análisis**: Se compara el resultado entre los grupos emparejados.


## 9. IPWRA {auto-animate="true"}

- El **IPTW** *(Inverse Probability of Treatment Weighting)* es una técnica
que utiliza las puntuaciones de propensión para asignar pesos a los
sujetos, permitiendo estimar el efecto causal del tratamiento en una
población equilibrada.

## 9. IPWRA {auto-animate="true"}

::: {style="font-size:38px"}
1.  **Cálculo de las Puntuaciones de Propensión**: Al igual que en el
    PSM, se calculan las probabilidades de la exposición para cada
    sujeto.

2.  **Asignación de Pesos**:

    -   Sujeto tratado: Peso = 1 / Puntuación de Propensión
    -   Sujeto no tratado: Peso = 1 / (1 - Puntuación de Propensión)

3.  **Análisis Ponderado**: Se realiza el análisis del efecto del
    tratamiento usando los pesos asignados para ajustar las diferencias
    entre los grupos.
:::

# 10. Ejercicio práctico: programar un propensity score

## 10. Ejercicio práctico: programar un propensity score {auto-animate="true"}

::: {style="font-size:28px;"}
1.  Elegir qué variables deben estar equilibradas por población a nivel
    de azar.
2.  Crear una tabla con *TableOne* para ver las *SMD* y su nivel basal.
3.  Aplicar un algoritmo de clasificación para ver las propensiones
    (usaremos un **glm** para no complicarnos).
4.  Crear la probabilidad de clasificación.
5.  Crear una variable IPTW / matching según las necesidades.
6.  Rehacer *TableOne* pero esta vez con los pesos o las variables de
    matching, y volver a las *SMD*.
7.  Asegurar que los *SMD* de las variables del punto primero están por
    debajo de 0.1.
8.  Visualizar los IPWT e individuos extrañamente alejados.
:::
