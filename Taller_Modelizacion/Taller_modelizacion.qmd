---
title: "Modelizando"
format:
  revealjs:
    incremental: true  
    scrollable: true
    transition: slide
editor: 
  markdown: 
    wrap: 72
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
pacman::p_load(tidyverse)
```

# 1. Bases de modelización

## Bases de modelización

1.  Tener clara la pregunta
2.  Tener más o menos claras las variables que interfieren en el proceso
3.  Tener Una idea de la complejidad de la pregunta

# 2. Tipos de modelos

## Tipos de modelos

1.  Aprendizaje **supervisado**
2.  Aprendizaje **no supervisado**
3.  Aprendizaje **por refuerzo**

# 3. Aprendizaje supervisado

## Aprendizaje supervisado

"El aprendizaje supervisado es la tarea de crear una función que assigna
una entrada a una salida basándose en pares de entrada-salida de
ejemplo."

Kevin P. Murphy, *Machine Learning: A Probabilistic Perspective*

## Aprendizaje supervisado

-   ::: {style="color:#8ABF74;"}
    Relativamente, el tipo de modelo más fiable y conocido
    :::

-   ::: {style="color:#BF1E1A;"}
    Requiere de completa supervisión humana
    :::

-   ::: {style="color:#BF1E1A;"}
    Los datos pueden contener error humano, ergo los algoritmos aprendan
    incorrectamente
    :::

-   Tipos de modelos:

    -   **clasificación**: Variables factor.
    -   **regresion**: Variables numericas.

## Aprendizaje supervisado

::: columns
::: {.column width="50%"}
![](Imagenes/armas%20de%20destruccion%20matematica.jpg){width="328"}
:::

::: {.column width="50%"}
*"Los privilegiados son analizados por personas, las masas por
máquinas."*

**Cathy O'Neil**
:::
:::

## Aprendizaje supervisado

-   Educación: Despido de profesores en Washington DC y Chicago por dar
    demasiado peso en la fórmula las bajas calificaciones de los
    alumnos.
-   Justicia:
-   Política: microtargeting
-   Economía: sesgos en el crédito

# 4. Aprendizaje no supervisado

## Aprendizaje no supervisado

-   Analiza y agrupa conjuntos de datos sin etiquetar.

-   Se basan en distancias. (Euclídeas o mahalanobis)

-   ::: {style="color:#8ABF74;"}
    Solución ideal para el análisis de datos exploratorios.
    :::

-   ::: {style="color:#BF1E1A;"}
    Computacionalmente duros
    :::

-   ::: {style="color:#BF1E1A;"}
    La interpretación puede ser un infierno
    :::

## Aprendizaje no supervisado

## Aprendizaje no supervisado: Agrupación en clústeres

-   La agrupación en clústeres de k-medias
-   Agrupación en clústeres jerárquica (HCA)
-   Agrupación en clústeres probabilística (GMM)

## Aprendizaje no supervisado: Reglas de asociación

*Identifican la probabilidad de consumir un producto dado el consumo de
otro producto*

## Aprendizaje no supervisado: Reducción de dimensionalidad

-   Análisis de componentes principales (PCA)

Este método utiliza una transformación lineal para crear una nueva
representación de datos

-   Descomposición en valores singulares

factoriza una matriz, A, en tres matrices de rango inferior.

## Aprendizaje no supervisado, caso Target

::: columns
::: {.column width="50%"}
![](Imagenes/target.png){width="359"}
:::

::: {.column width="50%"}
1.  Fundada en 1962
2.  Es la sexta empresa de venta al por menor más grande de Estados
    Unidos.
3.  351.000 empleados
:::
:::

## Aprendizaje no supervisado, caso Target

![](Imagenes/tickets_compra_embarazo.png)

## Aprendizaje no supervisado, caso Target

![](Imagenes/tickets_compra_dinero.png)

## Aprendizaje no supervisado, caso Target

```{r }
Target_ejemplo <- tibble(
  ClienteID = 1:6,
  VitaminasPrenatales = c(1, 0, 0, 0, 1, 0),
  LocionSinFragancia = c(1, 0, 0, 0, 1, 0),
  JabonSinFragancia = c(0, 1, 0, 0, 1, 0),
  Calcio = c(0, 1, 0, 0, 1, 1),
  Panales = c(0, 0, 1, 0, 0, 1),
  Toallitas = c(0, 0, 1, 0, 0, 0)
)

knitr::kable(Target_ejemplo)

```

## Aprendizaje no supervisado, caso Target

```{r echo=TRUE}
# Aplicar K-means
set.seed(123) # Para reproducibilidad
kmeans_result <- stats::kmeans(Target_ejemplo[,-1], centers = 3)

# Añadir los resultados del cluster al dataframe
Target_ejemplo <- Target_ejemplo %>%  
  mutate(Cluster = as_factor(kmeans_result$cluster) ) %>% 
  select(ClienteID, Cluster, everything())
```

## Aprendizaje no supervisado, caso Target

```{r}
knitr::kable(Target_ejemplo)
```

## Aprendizaje no supervisado, caso Target

```{r}
Target_ejemplo %>%  
  pivot_longer(
    cols= -c(Cluster,ClienteID),
    names_to =  'Producto',
    values_to = 'Compra_NoCompra') %>% 
  mutate(Compra_NoCompra = as_factor(Compra_NoCompra) ) %>% 
  ggplot(aes(x= Cluster, y= Producto, fill= Compra_NoCompra ) ) +
  geom_tile()
```

# 5. Aprendizaje por refuerzo

## 5 Aprendizaje por refuerzo

-   Entrena al software para que tome decisiones a fin de lograr los
    mejores resultados.

-   Ensayo y error (Supervisado y no supervisado al mismo tiempo)

## Aprendizaje por refuerzo

1.  Sobresale en entornos complejos

2.  Optimiza de acuerdo con objetivos a largo plazo

3.  Requiere menos interacción humana

## Aprendizaje por refuerzo

{{< video /Imagenes/Mario_IA_1.mp4 >}}

## Aprendizaje por refuerzo

{{< video /Imagenes/Mario_IA_2.mp4 >}}

## Aprendizaje por refuerzo

{{< video /Imagenes/Pokemon_IA_1.mp4 >}}

## Aprendizaje por refuerzo

{{< video /Imagenes/Pokemon_IA_2.mp4 >}}

## Aprendizaje por refuerzo

{{< video /Imagenes/Pokemon_IA_3.mp4 >}}

# Tipos de modelos 2

## Tipos de modelos 2

|                              | Modelos explicativos                                                                                                                     | Modelos predictivos                                                                                                                                                                   |
|-------------------|---------------------------|--------------------------|
| Objetivos                    | Establecer relaciones causales                                                                                                           | Predecir diagnósticos actuales o resultados futuros                                                                                                                                   |
| Precaución                   | Las posibilidades de hallazgos (Error tipo I)                                                                                            | No ajuste: falta de generalizabilidad a nuevas poblaciones                                                                                                                            |
| Variables candidatas         | Un conjunto limitado de factores de riesgo y factores de confusión                                                                       | Un conjunto más amplio de predictores potenciales; es posible que algunos predictores no tengan una relación causal con el resultado.                                                 |
| Selección de variables       | Basada en hipótesis; no debe utilizar procedimientos de selección automatizados.                                                         | Exploratorio;puede utilizar procedimientos de selección automatizados, siempre con la correspondiente validación.                                                                     |
| Formas de ver el rendimiento | Tamaño de los coeficientes {J para los factores de riesgo individuales; nivel de significación para los factores de riesgo individuales. | Discriminación (p. ej., análisis ROC); calibración (p. ej., prueba de Hosmer-Lemeshow);bondad de ajuste (p. ej., R2, AIC); reclasificación (p. ej., índice de reclasificación neta);  |
| Validación                   | Se necesitan nuevos estudios para confirmar las relaciones causales individuales                                                         | Validación interna; muestreo dividido; validación cruzada; bootstrap; validación externa.                                                                                             |

## Tipos de modelos 2

::: columns
::: {.column width="50%"}
Los investigadores con objetivos objetivos explicativos se desvían
intentan optimizar métricas del modelo (como los valores R2 o áreas bajo
la curva ROC curva ROC) y descuidan cuestiones como la confusión.
:::

::: {.column width="50%"}
Los investigadores con objetivos predictivos se desvían preocupándose
por los coeficientes b coeficientes y valores p, y omiten omiten pasos
críticos como la calibración o la validación.
:::
:::

# Machine learning supervisado
